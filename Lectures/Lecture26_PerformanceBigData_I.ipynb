{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 26: Performance of big data problems I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "![](https://www.tensorflow.org/images/colab_logo_32px.png)\n",
    "[Run in colab](https://colab.research.google.com/drive/1vHw5g_D6goE6v42FTaEzKSJaqvieaNF-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(\"Last executed: \" + now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sometimes, theoretical solutions and algorithms cannot be used in practice.\n",
    "\n",
    "Particularly when dealing with \"big data\", the size of the datasets and the resources at our disposal impose more limits on what computations we can realistically do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Performance issues\n",
    "\n",
    "Even when a solution for a problem exists in theory, in practice we are bound by **limited resources**:\n",
    "\n",
    "- Memory size: can we keep everything we need in memory or do we need to write to the disk often?\n",
    "- CPU power: will the computation end in a reasonable time?\n",
    "- Network bandwidth: can we transfer everything we need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Just because we can solve a problem on a small dataset doesn't guarantee that we can do it for large ones!\n",
    "\n",
    "We must also consider the **scaling behaviour**: a dataset that is 10x larger may require much more than 10x longer to process.\n",
    "\n",
    "The way an algorithm scales with the size of the input is sometimes expressed in the asymptotic O (\"big oh\")-notation. For example:\n",
    "- $O(N)$: linear in the size of the input\n",
    "- $O(N^2)$: quadratic\n",
    "- $O(2^N)$: exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The choice of algorithm can have a significant effect in how it can handle large input data:\n",
    "\n",
    "![Diagram showing linear, logarithmic and quadratic growth, with the latter being much more pronounced](Lecture26_Images/complexities.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improving resources\n",
    "\n",
    "An obvious approach is to throw more resources at the problem: more memory, faster networks, better processors. However:\n",
    "- we need to make sure it's the right resource! (hence: profiling to understand resource consumption and bottlenecks)\n",
    "- not always available\n",
    "- other considerations e.g. energy consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cloud computing\n",
    "\n",
    "A paradigm that is becoming very popular recently is the use of **cloud resources**: storage and computing resources held remotely and available on request.\n",
    "\n",
    "We saw an example of this in Lecture 22 when downloading data from S3 (Amazon Web Services)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Major providers include Amazon Web Services, Microsoft Azure and Google Cloud Platform. They offer a variety of resources, such as:\n",
    "- Storage (both files and various databases)\n",
    "- Compute (virtual machines, clusters for parallel computing, GPUs)\n",
    "- Services (instances of popular programs like Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This offers several advantages:\n",
    "- Flexibility: resources can be requested as and when needed, and can be scaled up or down depending on requirements.\n",
    "- No maintenance: updates etc are usually taken care of automatically by the provider\n",
    "- Easy setup: can use a service without worrying about setting up the infrastructure for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, there are also considerations to keep in mind:\n",
    "- Cost: can be difficult to predict\n",
    "- Limited ability to customise (compared to setting it up yourself)\n",
    "- Geographical constraints for data storage and processing (e.g. latency, personal data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Alternative approaches\n",
    "\n",
    "Instead of using more or bigger resources, we could look at different kinds of technologies and computational approaches:\n",
    "- Different language(s), libraries, algorithms\n",
    "- GPUs\n",
    "- Clusters / parallel & distributed processing\n",
    "\n",
    "These usually involve more work in adapting the solution but, if effective, can yield important benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Breaking down the task\n",
    "\n",
    "A small resource (e.g. computer) can handle a small task:\n",
    "\n",
    "<img src=\"Lecture26_Images/task.png\" width=\"300px\" alt=\"A small task represented by a blue circle, matched to a small computer.\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Faced with a large task, instead of increasing resources...\n",
    "\n",
    "<img src=\"Lecture26_Images/task.png\" width=\"600px\" alt=\"A large task represented by a large blue circle, matched to a large computer.\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "...break it down into smaller tasks:\n",
    "\n",
    "<img src=\"Lecture26_Images/tasks_many.png\" width=\"500px\" alt=\"A large task being split into many smaller ones, each matched to a small computer.\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is still not trivial:\n",
    "\n",
    "- Does the algorithm support it?\n",
    "- Can we efficiently combine results?\n",
    "- Is there support for doing it on the hardware?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Changing algorithms\n",
    "\n",
    "- Reformulate in different steps that allow separation\n",
    "- Maximize degree of parallelism\n",
    "- Minimize communication\n",
    "- Maintain correctness, avoid problems e.g. deadlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MapReduce\n",
    "\n",
    "How do we efficiently break down big tasks and combine results?\n",
    "\n",
    "- Break down data into smaller chunks\n",
    "- Handle each chunk separately\n",
    "- Gather together results from smaller chunks\n",
    "- Combine smaller results to form result from whole input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Lecture26_Images/hadoop.png\" alt=\"Schematic of the Map Reduce approach taken from Park et al 2016.\"/>\n",
    "\n",
    "From Park et al., [\"In-Storage Computing for Hadoop MapReduce Framework: Challenges and Possibilities\"](https://ieeexplore.ieee.org/document/7524716) (2016, DOI:0.1109/TC.2016.2595566)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "- The size of big data poses difficulties on conventional processing.\n",
    "- Using more powerful resources is a possibility, but sometimes a paradigm change is needed.\n",
    "- Conversion (such as by distributing computation) is not always straightforward but frameworks offer support."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
